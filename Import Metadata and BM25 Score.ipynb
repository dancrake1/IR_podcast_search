{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082a4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer  # lemmatization\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4183a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('metadata.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a2aa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_uri</th>\n",
       "      <th>show_name</th>\n",
       "      <th>show_description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>rss_link</th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_description</th>\n",
       "      <th>duration</th>\n",
       "      <th>show_filename_prefix</th>\n",
       "      <th>episode_filename_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
       "      <td>Kream in your Koffee</td>\n",
       "      <td>A 20-something blunt female takes on the world...</td>\n",
       "      <td>Katie Houle</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
       "      <td>spotify:episode:000A9sRBYdVh66csG2qEdj</td>\n",
       "      <td>1: It’s Christmas Time!</td>\n",
       "      <td>On the first ever episode of Kream in your Kof...</td>\n",
       "      <td>12.700133</td>\n",
       "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
       "      <td>000A9sRBYdVh66csG2qEdj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:show:15iWCbU7QoO23EndPEO6aN</td>\n",
       "      <td>Morning Cup Of Murder</td>\n",
       "      <td>Ever wonder what murder took place on today in...</td>\n",
       "      <td>Morning Cup Of Murder</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://anchor.fm/s/b07181c/podcast/rss</td>\n",
       "      <td>spotify:episode:000HP8n3hNIfglT2wSI2cA</td>\n",
       "      <td>The Goleta Postal Facility shootings- January ...</td>\n",
       "      <td>See something, say something. It’s a mantra ma...</td>\n",
       "      <td>6.019383</td>\n",
       "      <td>show_15iWCbU7QoO23EndPEO6aN</td>\n",
       "      <td>000HP8n3hNIfglT2wSI2cA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:show:6vZRgUFTYwbAA79UNCADr4</td>\n",
       "      <td>Inside The 18 : A Podcast for Goalkeepers by G...</td>\n",
       "      <td>Inside the 18 is your source for all things Go...</td>\n",
       "      <td>Inside the 18 GK Media</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://anchor.fm/s/81a072c/podcast/rss</td>\n",
       "      <td>spotify:episode:001UfOruzkA3Bn1SPjcdfa</td>\n",
       "      <td>Ep.36 - Incorporating a Singular Goalkeeping C...</td>\n",
       "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
       "      <td>43.616333</td>\n",
       "      <td>show_6vZRgUFTYwbAA79UNCADr4</td>\n",
       "      <td>001UfOruzkA3Bn1SPjcdfa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:show:5BvKEjaMSuvUsGROGi2S7s</td>\n",
       "      <td>Arrowhead Live!</td>\n",
       "      <td>Your favorite podcast for everything @Chiefs! ...</td>\n",
       "      <td>Arrowhead Live!</td>\n",
       "      <td>['en-US']</td>\n",
       "      <td>https://anchor.fm/s/917dba4/podcast/rss</td>\n",
       "      <td>spotify:episode:001i89SvIQgDuuyC53hfBm</td>\n",
       "      <td>Episode 1: Arrowhead Live! Debut</td>\n",
       "      <td>Join us as we take a look at all current Chief...</td>\n",
       "      <td>58.189200</td>\n",
       "      <td>show_5BvKEjaMSuvUsGROGi2S7s</td>\n",
       "      <td>001i89SvIQgDuuyC53hfBm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:show:7w3h3umpH74veEJcbE6xf4</td>\n",
       "      <td>FBoL</td>\n",
       "      <td>The comedy podcast about toxic characters, wri...</td>\n",
       "      <td>Emily Edwards</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://www.fuckboisoflit.com/episodes?format=rss</td>\n",
       "      <td>spotify:episode:0025RWNwe2lnp6HcnfzwzG</td>\n",
       "      <td>The Lion, The Witch, And The Wardrobe - Ashley...</td>\n",
       "      <td>The modern morality tail of how to stay good f...</td>\n",
       "      <td>51.782050</td>\n",
       "      <td>show_7w3h3umpH74veEJcbE6xf4</td>\n",
       "      <td>0025RWNwe2lnp6HcnfzwzG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              show_uri  \\\n",
       "0  spotify:show:2NYtxEZyYelR6RMKmjfPLB   \n",
       "1  spotify:show:15iWCbU7QoO23EndPEO6aN   \n",
       "2  spotify:show:6vZRgUFTYwbAA79UNCADr4   \n",
       "3  spotify:show:5BvKEjaMSuvUsGROGi2S7s   \n",
       "4  spotify:show:7w3h3umpH74veEJcbE6xf4   \n",
       "\n",
       "                                           show_name  \\\n",
       "0                               Kream in your Koffee   \n",
       "1                              Morning Cup Of Murder   \n",
       "2  Inside The 18 : A Podcast for Goalkeepers by G...   \n",
       "3                                    Arrowhead Live!   \n",
       "4                                              FBoL    \n",
       "\n",
       "                                    show_description               publisher  \\\n",
       "0  A 20-something blunt female takes on the world...             Katie Houle   \n",
       "1  Ever wonder what murder took place on today in...   Morning Cup Of Murder   \n",
       "2  Inside the 18 is your source for all things Go...  Inside the 18 GK Media   \n",
       "3  Your favorite podcast for everything @Chiefs! ...         Arrowhead Live!   \n",
       "4  The comedy podcast about toxic characters, wri...           Emily Edwards   \n",
       "\n",
       "    language                                           rss_link  \\\n",
       "0     ['en']           https://anchor.fm/s/11b84b68/podcast/rss   \n",
       "1     ['en']            https://anchor.fm/s/b07181c/podcast/rss   \n",
       "2     ['en']            https://anchor.fm/s/81a072c/podcast/rss   \n",
       "3  ['en-US']            https://anchor.fm/s/917dba4/podcast/rss   \n",
       "4     ['en']  https://www.fuckboisoflit.com/episodes?format=rss   \n",
       "\n",
       "                              episode_uri  \\\n",
       "0  spotify:episode:000A9sRBYdVh66csG2qEdj   \n",
       "1  spotify:episode:000HP8n3hNIfglT2wSI2cA   \n",
       "2  spotify:episode:001UfOruzkA3Bn1SPjcdfa   \n",
       "3  spotify:episode:001i89SvIQgDuuyC53hfBm   \n",
       "4  spotify:episode:0025RWNwe2lnp6HcnfzwzG   \n",
       "\n",
       "                                        episode_name  \\\n",
       "0                            1: It’s Christmas Time!   \n",
       "1  The Goleta Postal Facility shootings- January ...   \n",
       "2  Ep.36 - Incorporating a Singular Goalkeeping C...   \n",
       "3                   Episode 1: Arrowhead Live! Debut   \n",
       "4  The Lion, The Witch, And The Wardrobe - Ashley...   \n",
       "\n",
       "                                 episode_description   duration  \\\n",
       "0  On the first ever episode of Kream in your Kof...  12.700133   \n",
       "1  See something, say something. It’s a mantra ma...   6.019383   \n",
       "2  Today’s episode is a sit down Michael and Omar...  43.616333   \n",
       "3  Join us as we take a look at all current Chief...  58.189200   \n",
       "4  The modern morality tail of how to stay good f...  51.782050   \n",
       "\n",
       "          show_filename_prefix episode_filename_prefix  \n",
       "0  show_2NYtxEZyYelR6RMKmjfPLB  000A9sRBYdVh66csG2qEdj  \n",
       "1  show_15iWCbU7QoO23EndPEO6aN  000HP8n3hNIfglT2wSI2cA  \n",
       "2  show_6vZRgUFTYwbAA79UNCADr4  001UfOruzkA3Bn1SPjcdfa  \n",
       "3  show_5BvKEjaMSuvUsGROGi2S7s  001i89SvIQgDuuyC53hfBm  \n",
       "4  show_7w3h3umpH74veEJcbE6xf4  0025RWNwe2lnp6HcnfzwzG  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5434e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# pre-processing\n",
    "def pre_process(text):\n",
    "    punctuation_marks = string.punctuation.replace(\"'\", \"\")\n",
    "    \n",
    "    #converts to lower case\n",
    "    if preprocessing_switches['convert_to_lowercase']:    \n",
    "        text = text.lower()\n",
    "    \n",
    "    # separate punctuation from words - preserving apostrophe\n",
    "    if preprocessing_switches['separate_out_punctuation']:\n",
    "        for c in punctuation_marks:\n",
    "            text = text.replace(c, ' ' + c + ' ')\n",
    "    \n",
    "    #converting numbers to digits\n",
    "    if preprocessing_switches[\"convert_number_words_to_digits\"]:\n",
    "        text = text2int(text)   \n",
    "    \n",
    "    #removing numbers\n",
    "    if preprocessing_switches[\"convert_numbers\"]:\n",
    "        text = re.sub('\\d+', 'NUMBER',text)\n",
    "        text = text.replace('NUMBER ', '')\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    if preprocessing_switches['separate_out_punctuation']:    \n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    if preprocessing_switches['remove_punctuation']:    \n",
    "        tokens = [token for token in tokens if token not in punctuation_marks]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    if preprocessing_switches['apply_lemmatization']:\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "    # Stem the tokens\n",
    "    if preprocessing_switches['stem_tokens']:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093137e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_switches = {'convert_to_lowercase': True,\n",
    "                            'separate_out_punctuation': True,\n",
    "                            'remove_punctuation': True,\n",
    "                            'convert_number_words_to_digits': True,\n",
    "                            'convert_numbers': True,\n",
    "                            'remove_stopwords': True,\n",
    "                            'apply_lemmatization': True,\n",
    "                            'stem_tokens': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e20f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2int(textnum, numwords={}):\n",
    "    if not numwords:\n",
    "        units = [\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "        ]\n",
    "\n",
    "        tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "\n",
    "        scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "        numwords[\"and\"] = (1, 0)\n",
    "        for idx, word in enumerate(units):  numwords[word] = (1, idx)\n",
    "        for idx, word in enumerate(tens):       numwords[word] = (1, idx * 10)\n",
    "        for idx, word in enumerate(scales): numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
    "\n",
    "    ordinal_words = {'first':1, 'second':2, 'third':3, 'fifth':5, 'eighth':8, 'ninth':9, 'twelfth':12}\n",
    "    ordinal_endings = [('ieth', 'y'), ('th', '')]\n",
    "\n",
    "    textnum = textnum.replace('-', ' ')\n",
    "\n",
    "    current = result = 0\n",
    "    curstring = \"\"\n",
    "    onnumber = False\n",
    "    for word in textnum.split():\n",
    "        if word in ordinal_words:\n",
    "            scale, increment = (1, ordinal_words[word])\n",
    "            current = current * scale + increment\n",
    "            if scale > 100:\n",
    "                result += current\n",
    "                current = 0\n",
    "            onnumber = True\n",
    "        else:\n",
    "            for ending, replacement in ordinal_endings:\n",
    "                if word.endswith(ending):\n",
    "                    word = \"%s%s\" % (word[:-len(ending)], replacement)\n",
    "\n",
    "            if word not in numwords:\n",
    "                if onnumber:\n",
    "                    curstring += repr(result + current) + \" \"\n",
    "                curstring += word + \" \"\n",
    "                result = current = 0\n",
    "                onnumber = False\n",
    "            else:\n",
    "                scale, increment = numwords[word]\n",
    "\n",
    "                current = current * scale + increment\n",
    "                if scale > 100:\n",
    "                    result += current\n",
    "                    current = 0\n",
    "                onnumber = True\n",
    "\n",
    "    if onnumber:\n",
    "        curstring += repr(result + current)\n",
    "\n",
    "    return curstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc1f81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create subset for processing and apply pre-processing\n",
    "data_subset = data.loc[:10000]\n",
    "\n",
    "data_processed = data_subset['show_description'].apply(pre_process).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36925f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "documents_vectorized = vectorizer.fit_transform(data_processed)\n",
    "vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da789fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 7255)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(documents_vectorized.toarray(), columns=vocabulary)\n",
    "\n",
    "# removing low word counts to improve performance - low word counts also not likely to be relevant\n",
    "word_counts = dataframe.sum(axis=0)\n",
    "to_remove = word_counts[word_counts <4].index\n",
    "dataframe = dataframe.drop(columns = to_remove)\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c760787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#term frequencies\n",
    "dfs = (dataframe > 0).sum(axis=0)\n",
    "#idfs\n",
    "N = dataframe.shape[0]\n",
    "idfs = np.log10(N/dfs)\n",
    "#BM25\n",
    "k_1 = 1.2\n",
    "b = 0.8\n",
    "\n",
    "# The following line of code considers all words in each document:\n",
    "dls_all = [len(d.split(' ')) for d in data_processed] # vector\n",
    "\n",
    "# But we're not intrested in stop words, therefore, let's do the following: \n",
    "dls = dataframe.sum(axis=1).tolist()  # document lengths in words\n",
    "avgdl = np.mean(dls) # avarage document length\n",
    "\n",
    "numerator = np.array((k_1 + 1) * dataframe)\n",
    "denominator = np.array(k_1 *((1 - b) + b * (dls / avgdl))).reshape(N, 1) + \\\n",
    "                       np.array(dataframe)\n",
    "\n",
    "BM25_tf = numerator / denominator\n",
    "\n",
    "idfs = np.array(idfs)  # inverse document frequencies\n",
    "\n",
    "BM25_score = idfs * BM25_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7668c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7392     4.805475\n",
       "2077     3.856923\n",
       "6765     3.856923\n",
       "9530     3.856923\n",
       "2084     3.720322\n",
       "           ...   \n",
       "3335     0.000000\n",
       "3336     0.000000\n",
       "3337     0.000000\n",
       "3338     0.000000\n",
       "10000    0.000000\n",
       "Name: christmas, Length: 10001, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_idf = pd.DataFrame(BM25_score, columns=dataframe.columns)\n",
    "bm25_idf['christmas'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616e12d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_uri                                 spotify:show:2TPE8nsTVHyRkaVmQTbKbW\n",
       "show_name                                               61 Days of Christmas\n",
       "show_description           Hosts Abby and Kelsy watch the 40 new Hallmark...\n",
       "publisher                                      61 Days of Hallmark Christmas\n",
       "language                                                              ['en']\n",
       "rss_link                            https://anchor.fm/s/1004fcbc/podcast/rss\n",
       "episode_uri                           spotify:episode:0XgrKcGfkaf3cwGxkwKe5e\n",
       "episode_name                 Christmas Wishes & Mistletoe Kisses Snoozefest \n",
       "episode_description        Hosts Abby and Kelsy recount the exhausting fi...\n",
       "duration                                                           57.212417\n",
       "show_filename_prefix                             show_2TPE8nsTVHyRkaVmQTbKbW\n",
       "episode_filename_prefix                               0XgrKcGfkaf3cwGxkwKe5e\n",
       "Name: 7392, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[7392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b0ec189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_name</th>\n",
       "      <th>show_description</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>61 Days of Christmas</td>\n",
       "      <td>Hosts Abby and Kelsy watch the 40 new Hallmark...</td>\n",
       "      <td>61 Days of Hallmark Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>A Cup Of Cheer: A Seasonal Holiday Podcast</td>\n",
       "      <td>We don’t know if there will be snow, so have a...</td>\n",
       "      <td>DeeJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6765</th>\n",
       "      <td>A Cup Of Cheer: A Seasonal Holiday Podcast</td>\n",
       "      <td>We don’t know if there will be snow, so have a...</td>\n",
       "      <td>DeeJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9530</th>\n",
       "      <td>A Cup Of Cheer: A Seasonal Holiday Podcast</td>\n",
       "      <td>We don’t know if there will be snow, so have a...</td>\n",
       "      <td>DeeJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>MC Crue Podcast</td>\n",
       "      <td>On this podcast, we'll be talking about anythi...</td>\n",
       "      <td>Wolfpac Media</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       show_name  \\\n",
       "7392                        61 Days of Christmas   \n",
       "2077  A Cup Of Cheer: A Seasonal Holiday Podcast   \n",
       "6765  A Cup Of Cheer: A Seasonal Holiday Podcast   \n",
       "9530  A Cup Of Cheer: A Seasonal Holiday Podcast   \n",
       "2084                             MC Crue Podcast   \n",
       "\n",
       "                                       show_description  \\\n",
       "7392  Hosts Abby and Kelsy watch the 40 new Hallmark...   \n",
       "2077  We don’t know if there will be snow, so have a...   \n",
       "6765  We don’t know if there will be snow, so have a...   \n",
       "9530  We don’t know if there will be snow, so have a...   \n",
       "2084  On this podcast, we'll be talking about anythi...   \n",
       "\n",
       "                          publisher  \n",
       "7392  61 Days of Hallmark Christmas  \n",
       "2077                           DeeJ  \n",
       "6765                           DeeJ  \n",
       "9530                           DeeJ  \n",
       "2084                  Wolfpac Media  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'christmas'\n",
    "columns = ['show_name', 'show_description', 'publisher']\n",
    "\n",
    "query_words = pre_process(query).split(' ')\n",
    "top_results = bm25_idf[query_words].sum(axis = 1).sort_values(ascending = False).index[:5].tolist()\n",
    "data.loc[top_results, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a411d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine('sqlite:///IRDB', echo=False)\n",
    "# bm25_idf.to_sql('users', con=engine)\n",
    "\n",
    "(bm25_idf.memory_usage(deep = True).sum()) / (1024 * 1024)\n",
    "bm25_idf.to_csv('Web Page/BM25_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18726195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On this podcast, we'll be talking about anything and everything, especially what makes a movie a Christmas movie!   You can follow the guys on Instagram @mc.crue.podcast or e-mail us segment ideas at mccruepod@gmail.com  Cheers! \""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2084, 'show_description']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
